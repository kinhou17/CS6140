Problem02: Using the Rain in Australia data set, build a system that predicts whether it is going to rain tomorrow.  The labels are Column X in the CSV file.  Do not use Column W in your model, it directly correlates with Column X.
        For this problem, I used the Rain in Australia dataset to build a predictor of whether it will rain tomorrow. After examining the data, I realized the data required a lot of processing before it could be used in a regression model. I first changed the RainToday and RainTomorrow columns so that they would be in binary instead of “YES” and “NO”. I then checked for null values. I decided to drop 4 columns that had a significant number of null values as the data would be less useful with so many missing values. I then separated the columns into two datasets, one with the columns with numerical values, and the other containing the non-numerical categories. This was to be able to process the numerical categories’ null values. I decided on using the median strategy to fill these null values, as it seemed like a reasonable solution as to not pull the data towards one direction or the other in each category. After combining the two datasets back together, I took care of the categorical columns. The “Date” column was converted to months, to reflect seasonal changes, and also because I ended up converting categorical categories into binary categories, based on the range of answers in those categories. This way, “Date” would be turned into only 12 columns and could reflect seasonal changes, as opposed to having a column for every unique day in the data.
        I applied a minmax scaler for normalization due to the differences in ranges of values per category to reduce bias in the model. However, without it applied I didn’t find a significant difference in results. I tried two different classifiers, Random Forests and SGD, and Logistic Regression, a binary classifier (rain tomorrow is binary)  to the data and tested on the training set to see which performed best initially. What I found was that SGD performed the worst on the training set, with Random Forests and Logistic Regression performing similarly better. I decided to print the ROC curves as well, since they are a useful tool when dealing with binary classifiers. Both curves are quite similar. Overall, I found logistic regression tended to perform consistently the best with an F score of .582, however SGD and Random forest did not perform much worse, depending on the random shuffle of the training/test split.